{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZpIAXTLMYD6"
      },
      "source": [
        "# Language models\n",
        "\n",
        "Which word in the sequence is more likely:\n",
        "\n",
        "The train arrived at the\n",
        "* north \n",
        "* railway station\n",
        "\n",
        "Which sequence is more likely:\n",
        "* The train arrived at the station\n",
        "* The station arrived at the train\n",
        "\n",
        "The language model [language model, LM] allows you to estimate the probability of the next word in the sequence $P(w_n | w_1, \\ldots, w_{n-1})$ and estimate the probability of the entire sequence of words $P(w_1, \\ldots, w_n)$.\n",
        "\n",
        "### Applications:\n",
        "\n",
        "#### Tasks where complex and noisy input needs to be processed: \n",
        "* Speech recognition, \n",
        "* Recognition of scanned and handwritten texts;\n",
        "* Correction of typos\n",
        "* Machine translation\n",
        "* Tip when typing\n",
        "\n",
        "#### Types of models:\n",
        "* Countable models\n",
        "    - Markov chains\n",
        "* Neural network models, usually recurrent neural networks with LSTM/GRU \n",
        "* Seq2Seq architectures\n",
        "\n",
        "\n",
        "## Example\n",
        "\n",
        "![](https://github.com/artemovae/ML-for-compling/raw/668293ddcf40ef30461c45676ec1931c69551553/2018/img/aib.png)\n",
        "\n",
        "BOS А и Б сидели на трубе EOS\n",
        "\n",
        "BOS А упало Б пропало EOS\n",
        "\n",
        "BOS что осталось на трубе EOS\n",
        "\n",
        "$P($ и $| $ A $) = \\frac{1}{2}$\n",
        "\n",
        "$P($ Б $| $ и $) = \\frac{1}{1}$\n",
        "\n",
        "$P($ трубе $| $ на $) = \\frac{2}{2}$\n",
        "\n",
        "$P($ сидели $| $ Б $) = \\frac{1}{2}$\n",
        "\n",
        "$P($ на $| $ сидели $) = \\frac{1}{2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('BOS', 'А'),\n",
              " ('А', 'и'),\n",
              " ('и', 'Б'),\n",
              " ('Б', 'сидели'),\n",
              " ('сидели', 'на'),\n",
              " ('на', 'трубе'),\n",
              " ('трубе', 'EOS'),\n",
              " ('EOS', 'BOS'),\n",
              " ('BOS', 'А'),\n",
              " ('А', 'упало'),\n",
              " ('упало', 'Б'),\n",
              " ('Б', 'пропало'),\n",
              " ('пропало', 'EOS'),\n",
              " ('EOS', 'BOS'),\n",
              " ('BOS', 'что'),\n",
              " ('что', 'осталось'),\n",
              " ('осталось', 'на'),\n",
              " ('на', 'трубе'),\n",
              " ('трубе', 'EOS')]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(nltk.bigrams('''BOS А и Б сидели на трубе EOS\n",
        "\n",
        "BOS А упало Б пропало EOS\n",
        "\n",
        "BOS что осталось на трубе EOS'''.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM_Vhc7mrE6S",
        "outputId": "1e163831-824a-4968-ff6a-d90993306ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p(А и) = 0.5000\n",
            "p(и Б) = 1.0000\n",
            "p(на трубе) = 1.0000\n",
            "p(Б сидели) = 0.5000\n",
            "p(сидели на) = 1.0000\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "cfreq = nltk.ConditionalFreqDist(nltk.bigrams('''BOS А и Б сидели на трубе EOS\n",
        "\n",
        "BOS А упало Б пропало EOS\n",
        "\n",
        "BOS что осталось на трубе EOS'''.split()))\n",
        "\n",
        "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)\n",
        "print('p(А и) = %1.4f' %cprob['А'].prob('и'))\n",
        "print('p(и Б) = %1.4f' %cprob['и'].prob('Б'))\n",
        "print('p(на трубе) = %1.4f' %cprob['на'].prob('трубе'))\n",
        "print('p(Б сидели) = %1.4f' %cprob['Б'].prob('сидели'))\n",
        "print('p(сидели на) = %1.4f' %cprob['сидели'].prob('на'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rwiBCTAr4B4"
      },
      "source": [
        "**Now let us make dinosaurs!!!!!!!!!!!1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IFvhHIXaVepl",
        "outputId": "a9a91bd8-125d-46e2-8a43-ac029c4c9da8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'dinos (1).txt'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wget\n",
        "\n",
        "wget.download(\"https://raw.githubusercontent.com/artemovae/ML-for-compling/master/2018/dinos.txt\", \"dinos.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "JuFxsiYVKSFd"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBDzhvfeVW_C",
        "outputId": "1b83a45b-8da9-4dcd-df64-015550d5ebf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<aachenosaurus>', '<aardonyx>', '<abdallahsaurus>', '<abelisaurus>', '<abrictosaurus>', '<abrosaurus>', '<abydosaurus>', '<acanthopholis>', '<achelousaurus>', '<acheroraptor>']\n"
          ]
        }
      ],
      "source": [
        "names = ['<' + name.strip().lower() + '>' for name in open('dinos.txt').readlines()]\n",
        "print(names[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7kyQ4YWWh7T",
        "outputId": "5346956d-c8ef-4bf9-aabd-d08952a3f628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<', '>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ],
      "source": [
        "chars = [char  for name in names for char in name]\n",
        "freq = nltk.FreqDist(chars)\n",
        "\n",
        "print(sorted(list(freq.keys())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ud4mHY3Wt6g",
        "outputId": "ae1c04d2-4130-4d6c-9294-e4c0d5435db7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FreqDist({'u': 791, 'n': 347, 't': 204, 's': 171, 'l': 138, '>': 138, 'r': 124, 'c': 100, 'p': 89, 'm': 68, ...})"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(chars))\n",
        "cfreq['a']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPI3zlxTWx_s",
        "outputId": "56fdcd74-78a9-43dc-b68d-e2ea4c1466be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p(a a) = 0.0044\n",
            "p(a b) = 0.0097\n",
            "p(a u) = 0.3181\n"
          ]
        }
      ],
      "source": [
        "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)\n",
        "print('p(a a) = %1.4f' %cprob['a'].prob('a'))\n",
        "print('p(a b) = %1.4f' %cprob['a'].prob('b'))\n",
        "print('p(a u) = %1.4f' %cprob['a'].prob('u'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0cSPJPVW3Dl",
        "outputId": "a0241859-b94c-4fda-8803-1287a0f5763c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-13.275378042275806"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from math import log\n",
        "log(cprob['a'].prob('a')) + log(cprob['a'].prob('b')) + log(cprob['a'].prob('c'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHJ0tFiWX9Di",
        "outputId": "881a6265-eac2-4a7a-dcad-a008f24e5da6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FreqDist({'a': 2487, 's': 2285, 'u': 2123, 'o': 1710, 'r': 1704, '<': 1536, '>': 1536, 'n': 1081, 'i': 944, 'e': 913, ...})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADyZisM5Qddf",
        "outputId": "3347ba05-cbca-40af-bcab-c80310de606f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2487"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq['a']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nWZH8eyW7P5",
        "outputId": "e9f221e0-a690-4724-db1b-60d65f78b8a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p(a) = 0.1160\n"
          ]
        }
      ],
      "source": [
        "l = sum([freq[char] for char in freq])\n",
        "\n",
        "def unigram_prob(char):\n",
        "    return freq[char] / l\n",
        "\n",
        "print('p(a) = %1.4f' %unigram_prob('a'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_KlFlLrW9uT",
        "outputId": "8dc927f1-c636-4e02-8a73-757c9f9132fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('<', 'a'),\n",
              " ('a', 'a'),\n",
              " ('a', 'c'),\n",
              " ('c', 'h'),\n",
              " ('h', 'e'),\n",
              " ('e', 'n'),\n",
              " ('n', 'o'),\n",
              " ('o', 's'),\n",
              " ('s', 'a'),\n",
              " ('a', 'u'),\n",
              " ('u', 'r'),\n",
              " ('r', 'u'),\n",
              " ('u', 's'),\n",
              " ('s', '>')]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[bi for bi in nltk.bigrams('<aachenosaurus>')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K6VTbj6LJep-"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IhzfjqQQJhW_"
      },
      "outputs": [],
      "source": [
        "bigrams = [bi for bi in nltk.bigrams('aba caba baca bac')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYXh61WcJuTU",
        "outputId": "397c9555-91ab-4b3b-d312-0ae975445923"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fgiR6z6FKZ06"
      },
      "outputs": [],
      "source": [
        "ab = [bi for bi in bigrams if bi == ('a', 'b')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYdqNGpQKfVJ",
        "outputId": "69576cd0-b0d3-4607-abbb-4cce96f21865"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PkljrsbFLIG3"
      },
      "outputs": [],
      "source": [
        "chars = list('aba caba baca bac')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3Urgg6QJ4Td",
        "outputId": "b9bc1110-f7a0-4e75-ac59-6d0fd89b52a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p(a b) = 0.2857142857142857\n"
          ]
        }
      ],
      "source": [
        "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(chars))\n",
        "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)\n",
        "print(f\"p(a b) = {cprob['a'].prob('b')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a__2giahLynn",
        "outputId": "0ffbed20-15bf-4dd5-e5fc-085dc47677d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2857142857142857"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "2/7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cvPDuXhXaxO"
      },
      "source": [
        "### Task 1. \n",
        "\n",
        "1.1 Write a function to estimate the probability of a dinosaur name.\n",
        "\n",
        "1.2 Find the most likely dinosaur name from this list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7bBrGQBSYUqN"
      },
      "outputs": [],
      "source": [
        "def estimate_dino_prob(dinosaur_name):\n",
        "    prob = 1.0\n",
        "    for left, right in nltk.bigrams(dinosaur_name):\n",
        "        prob *= cprob[left].prob(right)\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pBbBAtsMYUtc"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/andreeva.dal/workspace/nlp_course/seminars/LMs.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andreeva.dal/workspace/nlp_course/seminars/LMs.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m estimate_dino_prob(\u001b[39m'\u001b[39m\u001b[39m<aachenosaurus>\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m estimate_dino_prob(\u001b[39m'\u001b[39m\u001b[39m<aachenosauril>\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "assert estimate_dino_prob('<aachenosaurus>') > estimate_dino_prob('<aachenosauril>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRQhkt85YVOX",
        "outputId": "06862fda-02e0-4f9d-d01a-4d3b917b6ab3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('<talos>', 2.639985626826119e-05)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(reversed(sorted([(dinosaur_name, estimate_dino_prob(dinosaur_name)) for dinosaur_name in names], key=lambda x: x[1])))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "1LM43VZ9XM2a"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "def compute_probability(word):\n",
        "    whole_probability = 1.0\n",
        "    for i, j in [bi for bi in nltk.bigrams(word)]:\n",
        "        #print('p(%s %s) = %1.4f' %(i, j, cprob[i].prob(j)))\n",
        "        whole_probability *= cprob[i].prob(j)\n",
        "    return whole_probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2Q2NnA0H-yE",
        "outputId": "abdc9e9c-b6b8-46c3-b0f0-5f524ad41052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('<talos>', 2.639985626826119e-05),\n",
              " ('<mei>', 2.112487234254014e-06),\n",
              " ('<elosaurus>', 1.8327456825026856e-06),\n",
              " ('<almas>', 7.361477189901781e-07),\n",
              " ('<balaur>', 6.732825877952762e-07)]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "probs = [(word, compute_probability(word)) for word in names]\n",
        "sorted(probs, key=lambda x: x[1], reverse=True)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oImb2MTBJ59S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jq4QLeKYMBr"
      },
      "source": [
        "## Recurrent Neural Networks (RNN)\n",
        "\n",
        "The original sequence:\n",
        "\n",
        "$x_{1:n} = x_1, x_2, \\ldots, x_n$, $x_i \\in \\mathbb{R}^{d_{in}}$\n",
        "\n",
        "-----------------------------------------\n",
        "\n",
        "For each input value $x_{1:i}$, we get $y_i$ at the output:\n",
        "\n",
        "$y_i = RUN(x_{1:i})$, $y_i \\in \\mathbb{R}^{d_{out}}$\n",
        "\n",
        "-----------------------------------------\n",
        "\n",
        "For the entire sequence $x_{1:n}$:\n",
        "\n",
        "$y_{1:n} = RN^{*}(x_{1:n})$, $y_i \\in \\mathbb{R}^{d_{out}}$\n",
        "\n",
        "$R$ is a recursive activation function depending on two parameters: $x_i$ and $s_{i-1}$ (the vector of the previous state)\n",
        "\n",
        "-----------------------------------------\n",
        "\n",
        "$RNN^{*}(x_{1:n}, s_0) = y_{1:n}$\n",
        "\n",
        "$y_i = O(s_i) = g(W^{out}[s_{i} ,x_i] +b)$\n",
        "\n",
        "$s_i = R(s_{i-1}, x_i)$\n",
        "\n",
        "$s_i = R(s_{i-1}, x_i) = g(W^{hid}[s_{i-1} ,x_i] +b)$ -- concatenation $[s_{i-1}, x]$\n",
        "\n",
        "$x_i \\in \\mathbb{R}^{d_{in}}$, $y_i \\in \\mathbb{R}^{ d_{out}}$, $s_i \\in \\mathbb{R}^{d_{hid}}$\n",
        "\n",
        "$W^{head} \\in \\mathbb{R}^{(d_{in}+d_{out}) \\times d_{hid}}$, $W^{out} \\in \\mathbb{R}^{d_{hid} \\times d_{out}}$\n",
        "\n",
        "Let's build a language model based on RNN using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jyTYPnwWagrF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pdb\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "torch.set_printoptions(linewidth=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KgmVlbE8SSDa"
      },
      "outputs": [],
      "source": [
        "random_seed = 381 \n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "t-_uDNimal0u"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "hidden_size = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb4JBPM4fUbE"
      },
      "source": [
        "Let us prepare a dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Mn_k8XFvfPVx"
      },
      "outputs": [],
      "source": [
        "class DinosDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        with open('dinos.txt') as f:\n",
        "            content = f.read().lower().strip()\n",
        "            self.vocab = sorted(set(content)) + ['<', '>']\n",
        "            self.vocab_size = len(self.vocab)\n",
        "            self.lines = content.splitlines()\n",
        "        self.ch_to_idx = {c:i for i, c in enumerate(self.vocab)}\n",
        "        self.idx_to_ch = {i:c for i, c in enumerate(self.vocab)}\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        line = self.lines[index]\n",
        "        #teacher forcing\n",
        "        x_str = '<' + line # x_1, x_2, x_3...\n",
        "        y_str = line + '>'  #x_2, x_3, x_4...\n",
        "        x = torch.zeros([len(x_str), self.vocab_size], dtype=torch.float)\n",
        "        y = torch.empty(len(x_str), dtype=torch.long)\n",
        "        for i, (x_ch, y_ch) in enumerate(zip(x_str, y_str)):\n",
        "            x[i][self.ch_to_idx[x_ch]] = 1\n",
        "            y[i] = self.ch_to_idx[y_ch]\n",
        "        \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "aJbMiCbtfSKs"
      },
      "outputs": [],
      "source": [
        "trn_ds = DinosDataset()\n",
        "trn_dl = DataLoader(trn_ds, shuffle=True, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "PUKenXbIfbOv",
        "outputId": "c892313b-9c85-47a4-edb4-084be7e30902"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'aardonyx'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trn_ds.lines[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayU77VTIUBSQ",
        "outputId": "cb1b2bcc-e1cd-45ce-e72a-49b279bb16e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\\n',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '<',\n",
              " '>']"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trn_ds.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N9FuUOthFf3",
        "outputId": "dd49f8e0-a8d3-4e39-d99a-080dc965a7ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trn_ds.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKFd9PLTfc5i",
        "outputId": "5a409ae4-c4c4-479a-d582-b3b5098c0d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: '<', 28: '>'}\n"
          ]
        }
      ],
      "source": [
        "print(trn_ds.idx_to_ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev_MZNgufio0",
        "outputId": "c6e82ef7-1581-4470-81bf-668d91b8b9ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([9, 29]),\n",
              " torch.Size([9]),\n",
              " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]),\n",
              " tensor([ 1,  1, 18,  4, 15, 14, 25, 24, 28]))"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x, y = trn_ds[1]\n",
        "x.shape, y.shape, x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-7eNpLDMeGh",
        "outputId": "eb510d10-6189-4de5-c963-6556e3ee057a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<', 'a', 'a', 'r', 'd', 'o', 'n', 'y', 'x', '>']"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[\"<\"] +[trn_ds.idx_to_ch[i] for i in [ 1,  1, 18,  4, 15, 14, 25, 24, 28]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST5WS0b8f3BC"
      },
      "source": [
        "Let us create the RRN model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "5T_QDHgEfrw7"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTMCell(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        # test\n",
        "        self.i2o = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, h_prev, x):\n",
        "        h, c = self.lstm(x, h_prev)\n",
        "        h = torch.tanh(h)\n",
        "        y = self.i2o(h)\n",
        "        return (h, c), y\n",
        "    \n",
        "    #def init_hidden()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "HUYimQZUf8nj"
      },
      "outputs": [],
      "source": [
        "model = RNN(trn_ds.vocab_size, hidden_size, trn_ds.vocab_size).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8bc2noGgJIf"
      },
      "source": [
        "![](https://github.com/PragmaticsLab/NLP-course-AMI/raw/0cb50728ceaa825f97d88f4e72efc954b817badc/seminars/sem4_language_models/images/dinos3.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "1_rCGfP7f-ci"
      },
      "outputs": [],
      "source": [
        "def sample(model):\n",
        "    model.eval()\n",
        "    word_size=0\n",
        "    newline_idx = trn_ds.ch_to_idx['>']\n",
        "    with torch.no_grad():\n",
        "        h_prev = (torch.zeros([1, hidden_size], dtype=torch.float, device=device),\n",
        "                  torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
        "                  )\n",
        "        x = h_prev[0].new_zeros([1, trn_ds.vocab_size])\n",
        "        start_char_idx = trn_ds.ch_to_idx['<']\n",
        "        indices = [start_char_idx]\n",
        "        x[0, start_char_idx] = 1\n",
        "        predicted_char_idx = start_char_idx\n",
        "        \n",
        "        while predicted_char_idx != newline_idx and word_size != 50:\n",
        "            h_prev, y_pred = model(h_prev, x)\n",
        "            y_softmax_scores = torch.softmax(y_pred, dim=1)\n",
        "            \n",
        "            np.random.seed(np.random.randint(1, 5000))\n",
        "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=y_softmax_scores.cpu().numpy().ravel())\n",
        "            indices.append(idx)\n",
        "            \n",
        "            x = (y_pred == y_pred.max(1)[0]).float()\n",
        "            #print(x)\n",
        "            \n",
        "            predicted_char_idx = idx\n",
        "            \n",
        "            word_size += 1\n",
        "        \n",
        "        if word_size == 50:\n",
        "            indices.append(newline_idx)\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "2hlddHN6gN-M"
      },
      "outputs": [],
      "source": [
        "def print_sample(sample_idxs):\n",
        "    [print(trn_ds.idx_to_ch[x], end ='') for x in sample_idxs]\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oga_CEQGgQWH"
      },
      "source": [
        "Let us train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "ITyuIlNhgOW1"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    for line_num, (x, y) in enumerate(trn_dl):\n",
        "        loss = 0\n",
        "        optimizer.zero_grad()\n",
        "        h_prev = (torch.zeros([1, hidden_size], dtype=torch.float, device=device),\n",
        "                  torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
        "                  )\n",
        "\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        for i in range(x.shape[1]):\n",
        "            h_prev, y_pred = model(h_prev, x[:, i])\n",
        "            loss += loss_fn(y_pred, y[:, i])\n",
        "            \n",
        "        if (line_num+1) % 100 == 0: \n",
        "            print_sample(sample(model))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    perplexity = torch.exp(loss)\n",
        "    print(f'Perplexity:{perplexity}') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "qrP-JhJtgW_6"
      },
      "outputs": [],
      "source": [
        "def train(model, loss_fn, optimizer, dataset='dinos', epochs=1):\n",
        "    for e in range(1, epochs+1):\n",
        "        print('Epoch:{}'.format(e))\n",
        "        train_one_epoch(model, loss_fn, optimizer)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fb_0WWlgZjT",
        "outputId": "7fa8c90e-90f9-4556-f040-ab1e12cd5a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1\n",
            "<uxanoaiuauiyabupapdulmauao>\n",
            "<rzcuuuriuup>\n",
            "<uosuwaopaluaun>\n",
            "<actoarguopa>\n",
            "<alyrvauuusnuus>\n",
            "<tmrsuaorap>\n",
            "<ashuabtraso>\n",
            "<hiatamvrucuuusr>\n",
            "<rkztnsuuassas>\n",
            "<ashuacuuaus>\n",
            "<hiatanuruauu>\n",
            "<lerrnysnuu>\n",
            "<ajlagtauo>\n",
            "<adsoaoaurso>\n",
            "<alvruesyusrs>\n",
            "Perplexity:513331462144.0\n",
            "\n",
            "Epoch:2\n",
            "<jytortsatsmu>\n",
            "<asguaeoucur>\n",
            "<glatanuswnsus>\n",
            "<eronytnts>\n",
            "<alibgsaurur>\n",
            "<snaoaurup>\n",
            "<anvruetuuseusuu>\n",
            "<lrruanaerur>\n",
            "<fuadoqaurus>\n",
            "<atanvrtnrus>\n",
            "<eronysaurup>\n",
            "<lbgsasaurus>\n",
            "<anathnaupus>\n",
            "<ucrsourus>\n",
            "<ztirrsaurus>\n",
            "Perplexity:8971356209152.0\n",
            "\n",
            "Epoch:3\n",
            "<asetaesraurus>\n",
            "<atanws>\n",
            "<cttskmcurus>\n",
            "<rtuaipaurus>\n",
            "<uabslaaurus>\n",
            "<tbiuosaurus>\n",
            "<rsixspauros>\n",
            "<alscrmtlrusaurus>\n",
            "<atanvsturus>\n",
            "<entrysaurur>\n",
            "<kbesasaurus>\n",
            "<anesaurus>\n",
            "<xrudourus>\n",
            "<snytmosrurus>\n",
            "<sbrltcauros>\n",
            "Perplexity:5.644894844485632e+16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train(model, loss_fn, optimizer, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL07Mt8_he2O"
      },
      "source": [
        "## Test model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhPGyAdvhd49",
        "outputId": "3faf3d5d-238a-4867-f7fe-69512c393b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sanaucaurus>\n"
          ]
        }
      ],
      "source": [
        "ids = sample(model)\n",
        "print_sample(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIS7nyvwgy8p"
      },
      "source": [
        "## Task 1.\n",
        "Rewrite the sampling function so that pangrams (words that contain each character of the alphabet only once)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b3Z6oWSg8W6"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "def sample(model):\n",
        "    model.eval()\n",
        "    word_size=0\n",
        "    newline_idx = trn_ds.ch_to_idx['>']\n",
        "    with torch.no_grad():\n",
        "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
        "        x = h_prev.new_zeros([1, trn_ds.vocab_size])\n",
        "        start_char_idx = trn_ds.ch_to_idx['<']\n",
        "        indices = [start_char_idx]\n",
        "        x[0, start_char_idx] = 1\n",
        "        predicted_char_idx = start_char_idx\n",
        "        \n",
        "        while predicted_char_idx != newline_idx and word_size != 50:\n",
        "            h_prev, y_pred = model(h_prev, x)\n",
        "            y_softmax_scores = torch.softmax(y_pred, dim=1)\n",
        "            \n",
        "            idx = indices[-1]\n",
        "            while idx in indices:\n",
        "                np.random.seed(np.random.randint(1, 5000))\n",
        "                idx = np.random.choice(np.arange(trn_ds.vocab_size), p=y_softmax_scores.cpu().numpy().ravel())\n",
        "            indices.append(idx)\n",
        "            \n",
        "            x = (y_pred == y_pred.max(1)[0]).float()\n",
        "            \n",
        "            predicted_char_idx = idx\n",
        "            \n",
        "            word_size += 1\n",
        "        \n",
        "        if word_size == 50:\n",
        "            indices.append(newline_idx)\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAfFlA53kjM5",
        "outputId": "bae2e961-8805-4da8-c511-07eccca50bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<tarkedlunis>\n"
          ]
        }
      ],
      "source": [
        "print_sample(sample(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgrQxISAgzP5"
      },
      "source": [
        "## Task 2.\n",
        "Rewrite the sampling function so that is it is possible to change the sampling temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yww3y4Y6jHF3"
      },
      "outputs": [],
      "source": [
        "def equalize_probs_sqrt(in_vector):\n",
        "    out_vector = np.zeros_like(in_vector)\n",
        "    for i, el in enumerate(in_vector):\n",
        "        out_vector[i] = np.math.sqrt(el)\n",
        "\n",
        "    return out_vector / sum(out_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$p_i = \\frac{exp(z_i / T)}{\\sum exp(z_j / T)}$ -- temperature sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "T = 1 -- standard softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "#def temp_softmax(y_pred, t):\n",
        "#    sum_ex = torch.sum(torch.exp(y_pred / t), axis=0)\n",
        "#    return torch.exp(y_pred / t) / sum_ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "uzEDyiVbg_MB"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "\n",
        "def sample(model, t):\n",
        "    model.eval()\n",
        "    word_size=0\n",
        "    newline_idx = trn_ds.ch_to_idx['>']\n",
        "    with torch.no_grad():\n",
        "        h_prev = (torch.zeros([1, hidden_size], dtype=torch.float, device=device),\n",
        "                  torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
        "                  )\n",
        "        x = h_prev[0].new_zeros([1, trn_ds.vocab_size])\n",
        "        start_char_idx = trn_ds.ch_to_idx['<']\n",
        "        indices = [start_char_idx]\n",
        "        x[0, start_char_idx] = 1\n",
        "        predicted_char_idx = start_char_idx\n",
        "        \n",
        "        while predicted_char_idx != newline_idx and word_size != 50:\n",
        "            h_prev, y_pred = model(h_prev, x)\n",
        "            y_softmax_scores = torch.softmax(y_pred / t, dim=1)\n",
        "            \n",
        "            np.random.seed(np.random.randint(1, 5000))\n",
        "            #np.random.seed(23)\n",
        "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=y_softmax_scores.cpu().numpy().ravel())\n",
        "            indices.append(idx)\n",
        "            \n",
        "            x = (y_pred == y_pred.max(1)[0]).float()\n",
        "            #print(x)\n",
        "            \n",
        "            predicted_char_idx = idx\n",
        "            \n",
        "            word_size += 1\n",
        "        \n",
        "        if word_size == 50:\n",
        "            indices.append(newline_idx)\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<aanslnaurus>\n"
          ]
        }
      ],
      "source": [
        "ids = sample(model, 0.4)\n",
        "print_sample(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b67Qs9XCgzhW"
      },
      "source": [
        "##Task 3.\n",
        "Implement the beam search for sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLivB9yEgbYz"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QL07Mt8_he2O",
        "TIS7nyvwgy8p",
        "AgrQxISAgzP5",
        "b67Qs9XCgzhW"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
